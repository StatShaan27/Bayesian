<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Berger – Chapter 1: Basic Concepts</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../style.css">
  <style>
    /* Chapter page specific styling */
    .chapter-contents {
      background: #1f1f1f;
      padding: 1em 1.5em;
      border-radius: 10px;
      margin-bottom: 2em;
      box-shadow: 0 4px 10px rgba(0,0,0,0.5);
    }
    .chapter-contents h3 {
      color: #c9a227; /* gold */
      margin-bottom: 0.5em;
    }
    .chapter-contents ul {
      padding-left: 1.5em;
    }
    .chapter-section {
      background: #2a2a2a;
      padding: 1.2em 1.5em;
      border-radius: 10px;
      margin-bottom: 2em;
      box-shadow: 0 4px 12px rgba(0,0,0,0.6);
    }
    .chapter-section h4 {
      color: #bb86fc; /* purple subheading */
      margin-top: 0;
      border-bottom: 2px solid #c9a227; /* gold underline */
      padding-bottom: 0.3em;
      margin-bottom: 0.8em;
    }
    .chapter-section p, .chapter-section ul {
      color: #e6e6e6;
    }
    .chapter-section a {
      color: #c9a227;
    }
  </style>
</head>
<body>

<header>
  <h1>Berger – Chapter 1: Basic Concepts</h1>
  <p>Summer Reading Project on Bayesian Statistics</p>
</header>

<nav>
  <a href="../index.html">Home</a>
  <a href="../notes.html">Books and Chapter Notes</a>
  <a href="../reports.html">Supporting Reference Reports</a>
  <a href="../projrep.html">Final project report</a>
</nav>

<section>
  <div class="chapter-contents">
    <h3>Contents</h3>
    <ul>
      <li><a href="#1">1. Introduction to Basic Elements </a></li>
      <li><a href="#2">2. Two concrete examples of Decision problems</a></li>
      <li><a href="#3">3. Grappling with the Tension between Decision Theory and Statistical Inference</a></li>
      <li><a href="#4">4. Concept of Bayesian Expected Loss</a></li>
      <li><a href="#4">5. Solving the Drug Demand Example</a></li>
      <li><a href="#4">6. Frequentist Risk</a></li>
      <li><a href="#4">7. Frequentist Risk in the Drug Demand Problem</a></li>
      <li><a href="#4">4. Concept of Bayesian Expected Loss</a></li>
      <li><a href="#4">4. Concept of Bayesian Expected Loss</a></li>
    </ul>
  </div>

  <div class="chapter-section" id="1">
    <section>
  <h4>1. State of nature</h4>
  <ul>
    <li>The <strong>unknown quantity</strong> that influences the outcome of a decision is called the <strong>state of nature</strong>, denoted \(\theta\).</li>
    <li>The <strong>set of all possible states of nature</strong> is denoted \(\Theta\). Think of it as the universe of scenarios that could possibly occur.</li>
    <li>Example: If you’re deciding whether to carry an umbrella, the state of nature is the weather tomorrow (\(\theta =\) “rain” or “sun”).</li>
  </ul>

  <h4>2. Parameter and parameter space</h4>
  <ul>
    <li>When you perform experiments to learn about \(\theta\), you assume your observations follow a <strong>probability distribution</strong> that depends on \(\theta\).</li>
    <li>In this context, \(\theta\) is called the <strong>parameter</strong>, and \(\Theta\) is the <strong>parameter space</strong>.</li>
    <li>Example: Measuring the mean weight of apples in a basket; the unknown mean weight is the parameter, and all plausible mean weights form the parameter space.</li>
  </ul>

  <h4>3. Actions</h4>
  <ul>
    <li><strong>Decisions</strong> are formally called <strong>actions</strong>, denoted \(a\).</li>
    <li>The <strong>set of all possible actions</strong> is denoted \(\mathcal{A}\).</li>
    <li>Example: Actions could be {carry umbrella, don’t carry umbrella}.</li>
  </ul>

  <h4>4. Loss function</h4>
  <ul>
    <li>A <strong>loss function</strong> \(L(\theta, a)\) quantifies the “cost” of taking action \(a\) when the true state of nature is \(\theta\).</li>
    <li>It formalizes the idea of making mistakes: choosing a suboptimal action leads to a positive loss.</li>
    <li>Example:
      <ul>
        <li>If it rains (\(\theta = \text{rain}\)) and you didn’t take an umbrella (\(a = \text{no umbrella}\)), the loss \(L(\theta, a)\) might be high (getting wet).</li>
        <li>If it’s sunny and you carried an umbrella, the loss is small (slightly inconvenient).</li>
      </ul>
    </li>
    <li>All loss functions are assumed to be <strong>bounded below</strong>, i.e., \(L(\theta, a) \ge -K > -\infty\), ensuring technical soundness.</li>
  </ul>

  <h4>Visualization</h4>
  <p>Imagine a simple <strong>decision map</strong>:</p>
  <p>
    State of Nature (\(\theta\)) → True world scenario (unknown)<br>
    &nbsp;&nbsp;&nbsp;&nbsp;↓<br>
    Observations (X) → Data informs your beliefs<br>
    &nbsp;&nbsp;&nbsp;&nbsp;↓<br>
    Actions (a) → Choices you can make<br>
    &nbsp;&nbsp;&nbsp;&nbsp;↓<br>
    Loss Function L(\(\theta, a\)) → Cost incurred based on action vs reality
  </p>
  <ul>
    <li><strong>Top layer:</strong> Reality (\(\theta\))</li>
    <li><strong>Middle layer:</strong> What you observe and learn</li>
    <li><strong>Bottom layer:</strong> Action you take, evaluated through loss</li>
  </ul>
</section>

  </div>





























  
  <div class="chapter-section" id="2">
   <section>
  <h4>Example 1: Estimating drug demand</h4>
  <ul>
    <li><strong>State of nature:</strong>
      <ul>
        <li>The unknown quantity is \(\theta_2\), the proportion of people who would buy the new drug.</li>
        <li>Parameter space: \(\Theta = [0,1]\) because proportions must lie between 0 and 1.</li>
      </ul>
    </li>
    <li><strong>Action:</strong>
      <ul>
        <li>The action is choosing an estimate \(a\) for \(\theta_2\).</li>
        <li>Action space: \(\mathcal{A} = [0,1]\).</li>
      </ul>
    </li>
    <li><strong>Loss function:</strong>
      <ul>
        <li>Asymmetric linear loss:
          \[
          L(\theta_2, a) =
          \begin{cases}
          \theta_2 - a & \text{if } \theta_2 - a \ge 0 \quad \text{(underestimate)} \\
          2(a - \theta_2) & \text{if } \theta_2 - a < 0 \quad \text{(overestimate)}
          \end{cases}
          \]</li>
        <li>Overestimating demand is twice as costly as underestimating.</li>
        <li>Loss measured in “utility units.”</li>
      </ul>
    </li>
    <li><strong>Experiment / Observations:</strong>
      <ul>
        <li>Sample survey of \(n\) people, observing \(X\) who would buy the drug.</li>
        <li>Model: \(X \sim \text{Binomial}(n, \theta_2)\).</li>
      </ul>
    </li>
    <li><strong>Prior information:</strong>
      <ul>
        <li>Historical data suggest new drugs capture 10–20% of the market.</li>
        <li>Uniform prior: \(\pi(\theta_2) = \text{Uniform}(0.1, 0.2)\).</li>
      </ul>
    </li>
  </ul>
  <p><strong>Visualization:</strong></p>
  <p>
    True demand \(\theta_2 \in [0,1]\)<br>
    &nbsp;&nbsp;&nbsp;&nbsp;↓<br>
    Sample survey → \(X \sim \text{Binomial}(n, \theta_2)\)<br>
    &nbsp;&nbsp;&nbsp;&nbsp;↓<br>
    Choose estimate \(a \in [0,1]\)<br>
    &nbsp;&nbsp;&nbsp;&nbsp;↓<br>
    Compute loss \(L(\theta_2, a)\) (asymmetric)
  </p>

  <h4>Example 2: Accepting/rejecting transistor shipment</h4>
  <ul>
    <li><strong>State of nature:</strong>
      <ul>
        <li>The unknown proportion of defective transistors: \(\theta = e\).</li>
        <li>Parameter space: \(\Theta = [0,1]\).</li>
      </ul>
    </li>
    <li><strong>Actions:</strong>
      <ul>
        <li>\(a_1 =\) accept the shipment</li>
        <li>\(a_2 =\) reject the shipment</li>
        <li>Action space: \(\mathcal{A} = \{a_1, a_2\}\)</li>
      </ul>
    </li>
    <li><strong>Loss function:</strong>
      <ul>
        <li>Accept: \(L(e, a_1) = 10 e\)</li>
        <li>Reject: \(L(e, a_2) = 1\)</li>
        <li>Accepting a bad lot is much more costly than rejecting unnecessarily.</li>
      </ul>
    </li>
    <li><strong>Experiment / Observations:</strong>
      <ul>
        <li>Sample \(n\) transistors, count defective \(X\).</li>
        <li>Assume \(X \sim \text{Binomial}(n, e)\) for small \(n\) relative to shipment size.</li>
      </ul>
    </li>
    <li><strong>Prior information:</strong>
      <ul>
        <li>Historical data suggest \(e \sim \text{Beta}(0.05, 1)\).</li>
      </ul>
    </li>
  </ul>
  <p><strong>Visualization:</strong></p>
  <p>
    Unknown defect proportion \(e \in [0,1]<br>
    &nbsp;&nbsp;&nbsp;&nbsp;↓<br>
    Sample \(n\) transistors → \(X\) defects observed<br>
    &nbsp;&nbsp;&nbsp;&nbsp;↓<br>
    Decision: Accept (\(a_1\)) or Reject (\(a_2\))<br>
    &nbsp;&nbsp;&nbsp;&nbsp;↓<br>
    Loss \(L(e, a) = \{10 e \text{ if accept}, 1 \text{ if reject}\}\)
  </p>

  <h4>Key points illustrated by these examples</h4>
  <ul>
    <li><strong>State of nature (parameter)</strong> is what you want to learn or react to.</li>
    <li><strong>Action</strong> is your decision or estimate.</li>
    <li><strong>Loss function</strong> quantifies the consequences of wrong actions—can be asymmetric or proportional.</li>
    <li><strong>Prior information</strong> captures historical knowledge and informs decisions.</li>
    <li><strong>Experiments/observations</strong> provide data to update beliefs or guide actions.</li>
  </ul>
  <p>These examples show how <strong>decision theory formalizes real-world problems</strong>, whether it’s estimating demand or quality control, integrating data, prior knowledge, and costs.</p>
</section>

  </div>





























  
  <div class="chapter-section" id="3">
    <section>
  <h4>Grappling with the tension between decision theory and statistical inference</h4>

  <h4>The main idea</h4>
  <ul>
    <li>In <strong>decision theory</strong>, we usually imagine a well-defined problem: choose an action, know the possible consequences, and write down a <strong>loss function</strong> and a <strong>prior</strong>. Then calculate the best action.</li>
    <li>In <strong>statistical inference</strong>, you don’t usually stop with a decision. Instead, you try to <em>summarize the evidence</em> in a way others can use for their own decisions. Example: a physicist measuring the speed of light reports an estimate and uncertainty for others to use.</li>
  </ul>

  <h4>Why statisticians avoid losses and priors</h4>
  <ul>
    <li>Many statisticians use statistical inference as a <strong>shield</strong>: they say, “we don’t need losses or priors, we just give the data summary.”</li>
    <li>But that’s risky because:
      <ul>
        <li><strong>Usability:</strong> Reports should be structured to be useful for decision-making. Classical tools sometimes fail.</li>
        <li><strong>Available information:</strong> Investigators often know something about losses or prior knowledge (e.g., medical trials).</li>
        <li><strong>Inference itself is a decision:</strong> Choosing how to report results (confidence interval, p-value, posterior) is an action, which implies losses, even if only the “loss” of miscommunicating evidence.</li>
      </ul>
    </li>
  </ul>

  <h4>Visualization</h4>
  <p>Imagine two layers:</p>
  <ul>
    <li><strong>Decision layer:</strong> Someone acts (policymaker, engineer, doctor). They need probabilities and consequences.</li>
    <li><strong>Inference layer:</strong> Statistician provides a “package” of evidence (confidence intervals, posteriors, likelihoods).</li>
  </ul>
  <p>The catch: if the inference layer ignores loss and prior information, the “package” may be clumsy, forcing the decision layer to struggle or misinterpret.</p>
  <p>Imagine attaching <strong>labels and dials</strong> to the package:</p>
  <ul>
    <li>Labels = what prior information went in.</li>
    <li>Dials = what losses matter for different users.</li>
  </ul>
  <p>Then the evidence can be plugged into many decisions.</p>

  <h4>Decision-theoretic twist</h4>
  <ul>
    <li>Even if priors and losses are banished from inference, decision theory sneaks back in.</li>
    <li>Many standard inference rules (confidence intervals, unbiased estimators) can be <em>re-expressed</em> as solutions to hidden decision problems with special loss functions.</li>
    <li>Thus, decision theory remains useful in analyzing inference.</li>
  </ul>

  <p>Big message: <strong>inference and decision are not separate universes</strong>. Inference is just a special kind of decision, where the action is “choose how to summarize the evidence.”</p>

  <p>This passage essentially pokes statisticians: don’t hide behind “objectivity.” Losses and priors are always present, either explicit or implicit.</p>
</section>

  </div>






























  
  <div class="chapter-section" id="4">
    <section>
  <h4>1. Concept of Bayesian Expected Loss</h4>
  <ul>
    <li>The <strong>unknown quantity</strong> is \(\theta\), which governs the outcome.</li>
    <li>At decision time, uncertainty in \(\theta\) is captured by a <strong>probability distribution</strong> \(\pi^*(\theta)\).
      <ul>
        <li>\(\pi^*(\theta)\) is usually the <strong>posterior distribution</strong> after observing data.</li>
        <li>If no data are available, it can be the prior \(\pi(\theta)\).</li>
      </ul>
    </li>
    <li>The <strong>expected loss</strong> of an action \(a\) is the average loss over all possible \(\theta\), weighted by \(\pi^*(\theta)\).</li>
  </ul>
  <p><strong>Mathematical definition:</strong></p>
  <p>
    \[
    \rho(\pi^*, a) = \mathbb{E}_{\pi^*}[L(\theta, a)] = \int_\Theta L(\theta, a)\, dF_{\pi^*}(\theta)
    \]
  </p>
  <ul>
    <li>\(L(\theta, a)\) is the <strong>loss function</strong>, and the integral computes the <strong>weighted average loss</strong>.</li>
    <li>Intuition: “Given my current belief about \(\theta\), how costly will this action be on average?”</li>
  </ul>

  <h4>2. Example 1: Drug demand (no data)</h4>
  <ul>
    <li>Believed distribution: \(\theta_2 \sim \text{Uniform}(0.1, 0.2)\)</li>
    <li>Loss function \(L(\theta_2, a)\) is <strong>asymmetric linear</strong>, as in the previous example.</li>
    <li>Bayesian expected loss:
      \[
      \rho(\pi, a) = \int_{0.1}^{0.2} L(\theta_2, a)\, \pi(\theta_2)\, d\theta_2
      \]
    </li>
    <li>The integral splits depending on \(a < \theta_2\) (underestimate) or \(a > \theta_2\) (overestimate), giving piecewise formulas.</li>
    <li>The decision-maker chooses \(a\) to <strong>minimize expected loss</strong>.</li>
  </ul>

  <h4>3. Example 3: Transistor shipment</h4>
  <ul>
    <li>Actions: \(a_1 =\) accept, \(a_2 =\) reject</li>
    <li>Losses: \(L(\theta_1, a_1) = -500\), \(L(\theta_2, a_1) = 1000\), etc.</li>
    <li>Bayesian expected loss:
      <p>
        \(\rho(\pi, a_1) = L(\theta_1, a_1)\pi(\theta_1) + L(\theta_2, a_1)\pi(\theta_2) = -500(0.9) + 1000(0.1) = -350\)
      </p>
      <p>
        \(\rho(\pi, a_2) = -300\)
      </p>
    </li>
    <li>Action \(a_1\) is better because it <strong>minimizes expected loss</strong>.</li>
  </ul>

  <h4>4. Key points</h4>
  <ul>
    <li>\(\pi^*\) represents the <strong>current belief</strong> (posterior) rather than just prior.</li>
    <li>Expected loss provides a <strong>decision rule</strong>: choose the action \(a\) that minimizes \(\rho(\pi^*, a)\).</li>
    <li>Assumes action does not influence \(\theta\); if it does, expected loss formula can be adjusted.</li>
  </ul>

  <h4>Visualization idea</h4>
  <p>
    θ ~ π*(θ)  ← current belief<br>
    &nbsp;&nbsp;&nbsp;&nbsp;↓<br>
    Action a chosen<br>
    &nbsp;&nbsp;&nbsp;&nbsp;↓<br>
    Loss L(θ, a)<br>
    &nbsp;&nbsp;&nbsp;&nbsp;↓<br>
    Average over θ → Bayesian expected loss ρ(π*, a)<br>
    &nbsp;&nbsp;&nbsp;&nbsp;↓<br>
    Decision: choose a to minimize ρ(π*, a)
  </p>
  <p><strong>Core principle:</strong> Bayesian decision-making = pick the action with minimum expected loss under your current beliefs. This unifies estimation, prediction, and classification under a single formal rule.</p>
</section>

  </div>

































  <div class="chapter-section" id="5">
    <section>
  <h4>Solving the Drug Demand Example: Minimizing Bayesian Expected Loss</h4>

  <h4>Step 1: Recall the setup</h4>
  <ul>
    <li>Unknown proportion: \(\theta_2 \in [0.1,0.2]\)</li>
    <li>Prior (uniform): \(\pi(\theta_2) = \text{Uniform}(0.1,0.2)\)</li>
    <li>Loss function (asymmetric linear):
      \[
      L(\theta_2, a) = 
      \begin{cases} 
      \theta_2 - a & \text{if } a \le \theta_2 \ (\text{underestimate})\\
      2(a - \theta_2) & \text{if } a > \theta_2 \ (\text{overestimate})
      \end{cases}
      \]
    </li>
    <li>Bayesian expected loss:
      \[
      \rho(a) = \int_{0.1}^{0.2} L(\theta_2, a) \pi(\theta_2)\, d\theta_2
      = \int_{0.1}^{0.2} L(\theta_2, a) \cdot 10\, d\theta_2
      \]
      (uniform density over width 0.1 gives 10)
    </li>
  </ul>

  <h4>Step 2: Split the integral</h4>
  <p>If \(a \in [0.1,0.2]\), split at \(\theta_2 = a\):</p>
  \[
  \rho(a) = \underbrace{\int_{0.1}^{a} 20(a-\theta_2) d\theta_2}_{\text{overestimate}} 
           + \underbrace{\int_{a}^{0.2} 10(\theta_2 - a) d\theta_2}_{\text{underestimate}}
  \]

  <h4>Step 3: Compute each integral</h4>
  <ul>
    <li>Overestimate part:
      \[
      \int_{0.1}^{a} 20 (a - \theta_2) d\theta_2 = 10 a^2 - 2 a + 0.1
      \]
    </li>
    <li>Underestimate part:
      \[
      \int_{a}^{0.2} 10 (\theta_2 - a) d\theta_2 = 5 a^2 - 2 a + 0.2
      \]
    </li>
    <li>Total expected loss:
      \[
      \rho(a) = (10 a^2 - 2 a + 0.1) + (5 a^2 - 2 a + 0.2) = 15 a^2 - 4 a + 0.3
      \]
    </li>
  </ul>

  <h4>Step 4: Minimize \(\rho(a)\)</h4>
  <ul>
    <li>Derivative:
      \[
      \frac{d\rho}{da} = 30 a - 4
      \]
    </li>
    <li>Set to 0:
      \[
      30 a - 4 = 0 \implies a = \frac{4}{30} \approx 0.1333
      \]
    </li>
    <li>Since \(0.133 \in [0.1,0.2]\), it is valid.</li>
  </ul>

  <h4>Step 5: Conclusion</h4>
  <p>The <strong>Bayesian estimate minimizing expected loss</strong> is:</p>
  <p>\(\boxed{a \approx 0.133}\)</p>
  <p>Intuition: Overestimating is more costly, so the optimal estimate is biased toward the lower bound of the prior interval.</p>
</section>

  </div>





























<div class="chapter-section" id="6">
  <section>
  <h4>1. Decision Rule</h4>
  <ul>
    <li>A <strong>decision rule</strong> \(\delta(X)\) is a function mapping observed data \(X\) to an action \(a \in \mathcal{A}\):
      \[
      \delta: \mathcal{X} \to \mathcal{A}, \quad a = \delta(X)
      \]
    </li>
    <li>In <strong>no-data problems</strong>, a decision rule is simply an action.</li>
    <li>Two rules are <strong>equivalent</strong> if they give the same action for all \(X\) under every possible \(\theta\).</li>
    <li>Example 1 (Drug demand): \(\delta(X) = X/n\) (sample proportion), does not use loss or prior.</li>
    <li>Example 2 (Transistor shipment):
      \[
      \delta(X) = 
      \begin{cases} 
      a_1 & \text{if } X/n \le 0.05 \\ 
      a_2 & \text{if } X/n > 0.05
      \end{cases}
      \]
    </li>
  </ul>

  <h4>2. Frequentist Risk Function</h4>
  <ul>
    <li>In the frequentist approach, \(\theta\) is fixed but unknown.</li>
    <li>Risk of a decision rule \(\delta\) is the expected loss over all possible data \(X\) given \(\theta\):
      \[
      R(\theta, \delta) = \mathbb{E}_\theta [L(\theta, \delta(X))] = \int L(\theta, \delta(x)) \, dP_\theta(x)
      \]
    </li>
    <li>Intuition: average loss if applying \(\delta(X)\) repeatedly on samples drawn from \(\theta\).</li>
    <li>Contrast with Bayesian expected loss:
      <ul>
        <li>Bayesian: average over \(\theta\) (posterior).</li>
        <li>Frequentist: average over \(X\) (data) with \(\theta\) fixed.</li>
      </ul>
    </li>
  </ul>

  <h4>3. Comparing Decision Rules</h4>
  <ul>
    <li><strong>Partial ordering via risk:</strong>
      <ul>
        <li>\(\delta_1\) is R-better than \(\delta_2\) if \(R(\theta, \delta_1) \le R(\theta, \delta_2)\) for all \(\theta\), with strict inequality for some \(\theta\).</li>
        <li>R-equivalent: risks are equal for all \(\theta\).</li>
      </ul>
    </li>
    <li><strong>Admissibility:</strong>
      <ul>
        <li>A rule \(\delta\) is admissible if no other rule has uniformly smaller risk.</li>
        <li>Inadmissible: some other rule is strictly better in risk for at least one \(\theta\).</li>
        <li>Many admissible rules exist; their risks may cross across \(\theta\).</li>
      </ul>
    </li>
  </ul>

  <h4>4. Visualization Idea</h4>
  <p>
    θ fixed (unknown)<br>
    &nbsp;&nbsp;&nbsp;↓<br>
    Decision rule δ(X) → action a<br>
    &nbsp;&nbsp;&nbsp;↓<br>
    Data X ~ Pθ  → distribution of X<br>
    &nbsp;&nbsp;&nbsp;↓<br>
    Compute expected loss over X → Risk R(θ, δ)
  </p>
  <p>Unlike Bayesian expected loss (single number per action), frequentist risk is a function over θ, showing performance across all possible states of nature.</p>

  <h4>5. Intuition</h4>
  <ul>
    <li>Bayesian: choose action minimizing <strong>average loss over θ</strong> given current belief.</li>
    <li>Frequentist: choose rule minimizing <strong>average loss over repeated samples X</strong> for every true θ.</li>
    <li>Admissibility ensures no other rule is uniformly better.</li>
  </ul>

  <h4>Decision Rule as a Statistic</h4>
  <ul>
    <li>A decision rule \(\delta(X)\) maps data \(X\) to an action \(a \in \mathcal{A}\).</li>
    <li>Since \(\delta(X)\) depends <strong>only on observed data</strong>, it is a <strong>function of the sample</strong>.</li>
    <li>Formally, a statistic is any measurable function of the data, so every decision rule is technically a statistic.</li>
    <li>Not every statistic is a decision rule:
      <ul>
        <li>Example: sample mean \(\bar{X}\) is a statistic.</li>
        <li>Becomes a decision rule when mapped to an action:
          \[
          \delta(X) = 
          \begin{cases} 
          \text{accept} & \bar{X} \le 0.05 \\ 
          \text{reject} & \bar{X} > 0.05
          \end{cases}
          \]
        </li>
      </ul>
    </li>
    <li>Intuition: statistic summarizes the data; decision rule uses that summary to make a choice. Estimators themselves are decision rules mapping data to an estimate.</li>
  </ul>
  <p>In short: <strong>decision rule \(\delta(X)\) is a statistic because it is a function of the sample.</strong></p>
</section>

</div>

































  <div class="chapter-section" id="7">
    <section>
  <h4>Frequentist Risk in the Drug Demand Problem</h4>

  <h4>Step 1: Recall the setup</h4>
  <ul>
    <li>Unknown proportion: \(\theta_2 \in [0.1, 0.2]\)</li>
    <li>Sample: \(X \sim \text{Binomial}(n, \theta_2)\)</li>
    <li>Decision rule (estimator): \(\delta(X) = X/n\) (sample proportion)</li>
    <li>Loss function (asymmetric linear):
      \[
      L(\theta_2, a) = 
      \begin{cases} 
      \theta_2 - a & \text{if } a \le \theta_2 \\ 
      2(a - \theta_2) & \text{if } a > \theta_2
      \end{cases}
      \]
    </li>
    <li>Frequentist risk:
      \[
      R(\theta_2, \delta) = \mathbb{E}_{\theta_2}[L(\theta_2, \delta(X))] = \sum_{x=0}^n L(\theta_2, \delta(x)) \, P_{\theta_2}(X=x)
      \]
    </li>
  </ul>

  <h4>Step 2: Express \(\delta(X)\) in the loss</h4>
  <ul>
    <li>With \(\delta(X) = X/n\):
      \[
      L(\theta_2, \delta(X)) = 
      \begin{cases} 
      \theta_2 - X/n & \text{if } X/n \le \theta_2\\
      2(X/n - \theta_2) & \text{if } X/n > \theta_2
      \end{cases}
      \]
    </li>
    <li>Binomial probability:
      \[
      P_{\theta_2}(X = x) = \binom{n}{x} \theta_2^x (1-\theta_2)^{n-x}
      \]
    </li>
  </ul>

  <h4>Step 3: Frequentist risk formula</h4>
  <p>
    \[
    R(\theta_2, \delta) = \sum_{x=0}^{\lfloor n \theta_2 \rfloor} (\theta_2 - x/n) \binom{n}{x} \theta_2^x (1-\theta_2)^{n-x} 
    + \sum_{x=\lfloor n \theta_2 \rfloor + 1}^{n} 2 (x/n - \theta_2) \binom{n}{x} \theta_2^x (1-\theta_2)^{n-x}
    \]
  </p>
  <ul>
    <li>First sum: <strong>underestimation</strong></li>
    <li>Second sum: <strong>overestimation</strong></li>
    <li>This expresses \(R(\theta_2, \delta)\) as a <strong>function of \(\theta_2\)</strong></li>
  </ul>

  <h4>Step 4: Special case (small \(n\))</h4>
  <ul>
    <li>Example: \(n=10\), \(\theta_2 = 0.15\)</li>
    <li>\(\lfloor n \theta_2 \rfloor = \lfloor 1.5 \rfloor = 1\)</li>
    <li>Underestimation: \(x = 0,1\)</li>
    <li>Overestimation: \(x = 2, \dots, 10\)</li>
    <li>Compute each term using the formula and sum to get \(R(\theta_2, \delta)\)</li>
  </ul>

  <h4>Step 5: Remarks</h4>
  <ul>
    <li>Unlike Bayesian expected loss (a single number), frequentist risk depends on \(\theta_2\).</li>
    <li>It tells us how “risky” the estimator \(\delta(X) = X/n\) is for every possible true \(\theta_2\).</li>
    <li>The risk can be plotted as a curve of \(R(\theta_2, \delta)\) vs \(\theta_2\).</li>
  </ul>
</section>

  </div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>

































  <div class="chapter-section" id="0">
  
</div>






























  <div class="chapter-section" id="0">
  
</div>






























  <div class="chapter-section" id="0">
  
</div>






























  <div class="chapter-section" id="0">
  
</div>

































  <div class="chapter-section" id="0">
  
</div>































  <div class="chapter-section" id="0">
  
</div>





























  <div class="chapter-section" id="0">
  
</div>































  <div class="chapter-section" id="0">
  
</div>

































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>
































  <div class="chapter-section" id="0">
  
</div>


  <div class="chapter-section" id="6">
    <section>
  <h4>1. Decision Rule</h4>
  <ul>
    <li>A <strong>decision rule</strong> \(\delta(X)\) is a function mapping observed data \(X\) to an action \(a \in \mathcal{A}\):
      \[
      \delta: \mathcal{X} \to \mathcal{A}, \quad a = \delta(X)
      \]
    </li>
    <li>In <strong>no-data problems</strong>, a decision rule is simply an action.</li>
    <li>Two rules are <strong>equivalent</strong> if they give the same action for all \(X\) under every possible \(\theta\).</li>
    <li>Example 1 (Drug demand): \(\delta(X) = X/n\) (sample proportion), does not use loss or prior.</li>
    <li>Example 2 (Transistor shipment):
      \[
      \delta(X) = 
      \begin{cases} 
      a_1 & \text{if } X/n \le 0.05 \\ 
      a_2 & \text{if } X/n > 0.05
      \end{cases}
      \]
    </li>
  </ul>

  <h4>2. Frequentist Risk Function</h4>
  <ul>
    <li>In the frequentist approach, \(\theta\) is fixed but unknown.</li>
    <li>Risk of a decision rule \(\delta\) is the expected loss over all possible data \(X\) given \(\theta\):
      \[
      R(\theta, \delta) = \mathbb{E}_\theta [L(\theta, \delta(X))] = \int L(\theta, \delta(x)) \, dP_\theta(x)
      \]
    </li>
    <li>Intuition: average loss if applying \(\delta(X)\) repeatedly on samples drawn from \(\theta\).</li>
    <li>Contrast with Bayesian expected loss:
      <ul>
        <li>Bayesian: average over \(\theta\) (posterior).</li>
        <li>Frequentist: average over \(X\) (data) with \(\theta\) fixed.</li>
      </ul>
    </li>
  </ul>

  <h4>3. Comparing Decision Rules</h4>
  <ul>
    <li><strong>Partial ordering via risk:</strong>
      <ul>
        <li>\(\delta_1\) is R-better than \(\delta_2\) if \(R(\theta, \delta_1) \le R(\theta, \delta_2)\) for all \(\theta\), with strict inequality for some \(\theta\).</li>
        <li>R-equivalent: risks are equal for all \(\theta\).</li>
      </ul>
    </li>
    <li><strong>Admissibility:</strong>
      <ul>
        <li>A rule \(\delta\) is admissible if no other rule has uniformly smaller risk.</li>
        <li>Inadmissible: some other rule is strictly better in risk for at least one \(\theta\).</li>
        <li>Many admissible rules exist; their risks may cross across \(\theta\).</li>
      </ul>
    </li>
  </ul>

  <h4>4. Visualization Idea</h4>
  <p>
    θ fixed (unknown)<br>
    &nbsp;&nbsp;&nbsp;↓<br>
    Decision rule δ(X) → action a<br>
    &nbsp;&nbsp;&nbsp;↓<br>
    Data X ~ Pθ  → distribution of X<br>
    &nbsp;&nbsp;&nbsp;↓<br>
    Compute expected loss over X → Risk R(θ, δ)
  </p>
  <p>Unlike Bayesian expected loss (single number per action), frequentist risk is a function over θ, showing performance across all possible states of nature.</p>

  <h4>5. Intuition</h4>
  <ul>
    <li>Bayesian: choose action minimizing <strong>average loss over θ</strong> given current belief.</li>
    <li>Frequentist: choose rule minimizing <strong>average loss over repeated samples X</strong> for every true θ.</li>
    <li>Admissibility ensures no other rule is uniformly better.</li>
  </ul>

  <h4>Decision Rule as a Statistic</h4>
  <ul>
    <li>A decision rule \(\delta(X)\) maps data \(X\) to an action \(a \in \mathcal{A}\).</li>
    <li>Since \(\delta(X)\) depends <strong>only on observed data</strong>, it is a <strong>function of the sample</strong>.</li>
    <li>Formally, a statistic is any measurable function of the data, so every decision rule is technically a statistic.</li>
    <li>Not every statistic is a decision rule:
      <ul>
        <li>Example: sample mean \(\bar{X}\) is a statistic.</li>
        <li>Becomes a decision rule when mapped to an action:
          \[
          \delta(X) = 
          \begin{cases} 
          \text{accept} & \bar{X} \le 0.05 \\ 
          \text{reject} & \bar{X} > 0.05
          \end{cases}
          \]
        </li>
      </ul>
    </li>
    <li>Intuition: statistic summarizes the data; decision rule uses that summary to make a choice. Estimators themselves are decision rules mapping data to an estimate.</li>
  </ul>
  <p>In short: <strong>decision rule \(\delta(X)\) is a statistic because it is a function of the sample.</strong></p>
</section>

  </div>














  













  
</section>

<footer>
  &copy; 2025 Mohammad Shaan | Hosted on GitHub Pages
</footer>

<!-- MathJax for LaTeX -->
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

</body>
</html>
